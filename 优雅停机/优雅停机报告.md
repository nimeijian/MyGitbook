# 一、优雅停机

以下应用必须使用kill -9 pid命令进行强杀，需要做到优雅停机：

daizhang.biz

daizhang.task

daizhang.report

## 1、分析&解决

### 1.1 daizhang.biz

为了定位该问题，我们可以先使用kill pid命令停止服务，等待一段时间后，打堆栈，看下还有哪些用户线程处于RUNNABLE状态。

我们先找到Tomcat服务的进程id，因本地可能会有多个java.exe进程，可以使用jvisualvm查看具体哪个是Tomcat进程：

![](https://uploader.shimo.im/f/yQMT6bT0QbAykdxZ.png!thumbnail)

打线程堆栈：

![](https://uploader.shimo.im/f/FtUdbMK9kCkttEng.png!thumbnail)

以下是完整的堆栈文档：

[15416.txt](https://uploader.shimo.im/f/2OY1gzM8sHwTYagT.txt)

我们剔除掉daemon线程和非RUNNABLE状态线程后，得到以下用户线程还在跑：

```
"qtp666649918-685-selector-ClientSelectorManager@12703b8f/1" #685 prio=5 os_prio=0 tid=0x0000000047624000 nid=0x4018 runnable [0x0000000064f3e000]
   java.lang.Thread.State: RUNNABLE
	at sun.nio.ch.WindowsSelectorImpl$SubSelector.poll0(Native Method)
	at sun.nio.ch.WindowsSelectorImpl$SubSelector.poll(WindowsSelectorImpl.java:296)
	at sun.nio.ch.WindowsSelectorImpl$SubSelector.access$400(WindowsSelectorImpl.java:278)
	at sun.nio.ch.WindowsSelectorImpl.doSelect(WindowsSelectorImpl.java:159)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
	- locked <0x00000000fe5b5990> (a sun.nio.ch.Util$3)
	- locked <0x00000000fe5b5980> (a java.util.Collections$UnmodifiableSet)
	- locked <0x00000000fe5b5820> (a sun.nio.ch.WindowsSelectorImpl)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
	at org.eclipse.jetty.io.SelectorManager$ManagedSelector.select(SelectorManager.java:601)
	at org.eclipse.jetty.io.SelectorManager$ManagedSelector.run(SelectorManager.java:550)
	at org.eclipse.jetty.util.thread.NonBlockingThread.run(NonBlockingThread.java:52)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555)
	at java.lang.Thread.run(Thread.java:748)


   Locked ownable synchronizers:
	- None

"qtp666649918-684-selector-ClientSelectorManager@12703b8f/0" #684 prio=5 os_prio=0 tid=0x0000000047620000 nid=0x26c4 runnable [0x0000000064e3f000]
   java.lang.Thread.State: RUNNABLE
	at sun.nio.ch.WindowsSelectorImpl$SubSelector.poll0(Native Method)
	at sun.nio.ch.WindowsSelectorImpl$SubSelector.poll(WindowsSelectorImpl.java:296)
	at sun.nio.ch.WindowsSelectorImpl$SubSelector.access$400(WindowsSelectorImpl.java:278)
	at sun.nio.ch.WindowsSelectorImpl.doSelect(WindowsSelectorImpl.java:159)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
	- locked <0x00000000fe5cce08> (a sun.nio.ch.Util$3)
	- locked <0x00000000fe5ccdf8> (a java.util.Collections$UnmodifiableSet)
	- locked <0x00000000fe5b41f0> (a sun.nio.ch.WindowsSelectorImpl)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
	at org.eclipse.jetty.io.SelectorManager$ManagedSelector.select(SelectorManager.java:601)
	at org.eclipse.jetty.io.SelectorManager$ManagedSelector.run(SelectorManager.java:550)
	at org.eclipse.jetty.util.thread.NonBlockingThread.run(NonBlockingThread.java:52)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555)
	at java.lang.Thread.run(Thread.java:748)


   Locked ownable synchronizers:
	- None

"AMQP Connection 172.23.0.186:5672" #305 prio=5 os_prio=0 tid=0x000000002b4e1800 nid=0x40dc runnable [0x000000004593f000]
   java.lang.Thread.State: RUNNABLE
	at java.net.SocketInputStream.socketRead0(Native Method)
	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
	at java.net.SocketInputStream.read(SocketInputStream.java:171)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	- locked <0x00000000944188a0> (a java.io.BufferedInputStream)
	at java.io.DataInputStream.readUnsignedByte(DataInputStream.java:288)
	at com.rabbitmq.client.impl.Frame.readFrom(Frame.java:95)
	at com.rabbitmq.client.impl.SocketFrameHandler.readFrame(SocketFrameHandler.java:139)
	- locked <0x0000000094418880> (a java.io.DataInputStream)
	at com.rabbitmq.client.impl.AMQConnection$MainLoop.run(AMQConnection.java:536)
	at java.lang.Thread.run(Thread.java:748)

   Locked ownable synchronizers:
	- None
```

这里总共有3个用户线程，前两个是同一类型的，所以我们有两类线程需要停止掉，我们先看第一个线程堆栈，根据堆栈提示我们找到SelectorManager.java:550：

![](https://uploader.shimo.im/f/f0uJEslcItYPe10j.png!thumbnail)

由第546行和线程名qtp666649918-685-selector-ClientSelectorManager@12703b8f/1可知，这里运行的应该是ClientSelectorManager类，我们找到该类，我们在该类的构造方法上打断点，以查看运行时调用栈：

![](https://uploader.shimo.im/f/JuznRdK0YKQy19EB.png!thumbnail)

由以上调用栈可知，一个ClientSelectorManager对应一个jettyHttpClient，就是说有jettyHttpClient没有正常关闭，系统被kill pid后无法debug，我们可以下载相关第三方源码，并切换到我们应用所使用的Tag后在源码里打日志和调用栈：

![](https://uploader.shimo.im/f/Vj90vjImedgAMOLx.png!thumbnail)

并在入口类里打日志和调用栈：

![](https://uploader.shimo.im/f/lUPL6rQUJr8mM0s8.png!thumbnail)

我们先清空日志文件，然后启停服务，一段时间后我们查看日志文件：

![](https://uploader.shimo.im/f/lQzpJ618O9Q2e9up.png!thumbnail)

发现XxxJob&gt;&gt;&gt;&gt;&gt;&gt;jettyHttpClient.start\(\)打印了2次，而XxxJob&gt;&gt;&gt;&gt;&gt;&gt;jettyHttpClient.stop\(\)只打印了1次，所以有jettyHttpClient开启了却没有关闭，我们看第2次打印的jettyHttpClient.start\(\)前后的日志：

![](https://uploader.shimo.im/f/PtUrcuO802A3TA1K.png!thumbnail)

我们发现，registryThread线程已经被stop了，jettyHttpClient却又start了，而jettyHttpClient是在registryThread线程里start的，说明registryThread并没有阻止jettyHttpClient的start，我们查看源码可以验证这一点：

![](https://uploader.shimo.im/f/x9jQoSEKPOoqtnGw.png!thumbnail)

会等待registryThread执行完毕，所以registryThread线程会继续start jettyHttpClient，我们查看jettyHttpClient和registryThread分别在哪里关闭的，最后定位到下面的方法：

![](https://uploader.shimo.im/f/dTwE66xZVVEMNZK5.png!thumbnail)

这里先关闭xxlRpcInvokerFactory，再关闭xxlRpcProviderFactory，它们分别对应jettyHttpClient和registryThread线程的关闭，但我们希望先关闭registryThread再关闭jettyHttpClient，否则后面又start的jettyHttpClient就没有地方关闭它了，于是，我们调整下这两个XxlRpcFactory的关闭顺序：

![](https://uploader.shimo.im/f/9Hw6R6yDFlUd1uqf.png!thumbnail)

这样确保jettyHttpClient一定会被关闭，即使registryThread stop后又start了jettyHttpClient。

清空日志文件后，重新启停服务，然后打印堆栈并查看日志文件。通过查看堆栈，我们发现只剩一个RUNNABLE状态的用户线程AMQP Connection 172.23.0.186:5672，说明如上解决方法是正确的。也可以通过查看日志文件进一步验证，我们发现registryThread.start\(\)、jettyHttpClient.start\(\)、registryThread.stop\(\)、jettyHttpClient.stop\(\)都只打印了一次，而且它们执行的先后顺序为：

> 2019-05-29 16:00:40,303 c.x.j.c.t.ExecutorRegistryThread \[ExecutorRegistryThread.java : 43\] XxxJob
> registryThread.start\(\)

> 2019-05-29 16:00:40,893 com.xxl.rpc.remoting.net.Client \[JettyClient.java : 153\] XxxJob
> jettyHttpClient.start\(\)

> 2019-05-29 16:03:27,492 c.x.j.c.t.ExecutorRegistryThread \[ExecutorRegistryThread.java : 115\] XxxJob
> registryThread.stop\(\)

> 2019-05-29 16:03:27,517 com.xxl.rpc.remoting.net.Client \[JettyClient.java : 163\] XxxJob
> jettyHttpClient.stop\(\)

至此，qtp666649918-684-selector-ClientSelectorManager@12703b8f/0类线程已解决。

但出于尽量不要修改第三方源码考虑（版本升级不方便），这里采用另一种方式解决该问题：

```
@Component
public class YzfXxlRpcSpringInvokerFactory extends XxlRpcSpringInvokerFactory {

    @Override
    public void destroy() throws Exception {
        super.destroy();
    }
}
```

在容器关闭前再destroy一次Invoker端线程，如jettyHttpClient，经过测试可以达到同样的效果。

注：看了xxl-job的最新代码，2.0.2版本特意针对执行器优雅停机进行了优化，解决方法正是调整xxlRpcProviderFactory和XxlRpcInvokerFactory的stop顺序，经过本地验证，该问题可以通过升级xxl-job版本解决。

GitHub提交记录：

[https://github.com/xuxueli/xxl-job/commit/5368b6917e2902728289cbd22ebf860c9410d893\#diff-8fc1f6537a80654c323d93d4bb8e17d6R1433](https://github.com/xuxueli/xxl-job/commit/5368b6917e2902728289cbd22ebf860c9410d893#diff-8fc1f6537a80654c323d93d4bb8e17d6R1433)

XxlJobExecutor.java最新代码：

[https://github.com/xuxueli/xxl-job/blob/master/xxl-job-core/src/main/java/com/xxl/job/core/executor/XxlJobExecutor.java](https://github.com/xuxueli/xxl-job/blob/master/xxl-job-core/src/main/java/com/xxl/job/core/executor/XxlJobExecutor.java)



下面解决AMQP Connection 172.23.0.186:5672线程，解决方法类似，也是通过IDEA debug查看调用栈、通过git clone第三方源码后打印日志和调用栈等方式来定位，大胆、灵活假设各种原因，细心、严谨求证。最终定位原因如下：

![](https://uploader.shimo.im/f/2B75SPbXHb0WFyDn.png!thumbnail)

这里业务代码里自己new了个CachingConnectionFactory，自己new出来的，Spring是不会替我们管理的，比如不会在容器Closed的时候执行destroy方法并停止用户线程，所以这里的修改方法就是，通过Spring容器注入CachingConnectionFactory：

![](https://uploader.shimo.im/f/0jhbUKADbA4YTra6.png!thumbnail)

这是个较低级的错误，写代码时需要引以为戒。

### 1.2 daizhang.task

该应用遇到的问题及解决方法参考如下文章：

[https://blog.csdn.net/weixin\_33859504/article/details/87010398](https://blog.csdn.net/weixin_33859504/article/details/87010398)

原因解释：

有个线程池工厂（Executors.defaultThreadFactory\(\)）创建的是非守护线程，所有的非守护线程必须调用相应的方法成功关闭后JVM才会退出，但dubbo为了规避netty的一个bug，将这个关闭方法注掉了，并希望在shutdownhook里调用这个关闭方法，问题就出在这儿：因为那些非守护线程没有关闭，所以JVM不会调用这个shutdownhook方法（死循环了，JVM只有在所有的非守护线程都结束后才会调用shutdownhook方法并结束掉所有的守护线程后退出），因为有非守护线程没有成功关闭，所以JVM不能优雅退出。

具体代码如下：

```
@Component
public class DubboShutdown implements ApplicationListener<ContextClosedEvent> {
    private static final Logger LOGGER = LoggerFactory.getLogger(DubboShutdown.class);

    @Override
    public void onApplicationEvent(ContextClosedEvent contextClosedEvent) {
        if(contextClosedEvent.getApplicationContext().getParent() != null) {
            return;
        }

        //先释放dubbo所占用的资源
        ProtocolConfig.destroyAll();

        //用反射释放NettyClient所占用的资源, 以避免不能优雅shutdown的问题
        releaseNettyClientExternalResources();

        // 上面ProtocolConfig.destroyAll()已经unregisted了dubbo服务，后面dubbo又会再次在它的Shutdownhook里unregisted这些dubbo服务，会抛异常，这里忽略该异常，不显示在控制台或日志文件里
        CuratorZookeeperClient.setIgnoreError(true);
    }

    private void releaseNettyClientExternalResources() {
        try {
            Field field = NettyClient.class.getDeclaredField("channelFactory");
            field.setAccessible(true);
            ChannelFactory channelFactory = (ChannelFactory) field.get(NettyClient.class);
            channelFactory.releaseExternalResources();
            field.setAccessible(false);
            LOGGER.info("Release NettyClient's external resources");
        } catch (Exception e){
            LOGGER.error("Release NettyClient's external resources error", e);
        }
    }
}
```

### 1.3 daizhang.report

以上问题都解决后，该应用没有其它问题，可以优雅停机。

## 2、拓展

### 2.1 用户线程&守护线程

JVM只有当用户线程完全退出后，才会执行ShutdownHook并退出守护线程，最终结束JVM。

所以，用户线程必须能够退出，退出线程的方法：[https://blog.csdn.net/anhuidelinger/article/details/11746365](https://blog.csdn.net/anhuidelinger/article/details/11746365)。

用户线程和守护线程的区别：[https://blog.csdn.net/dream\_broken/article/details/8913563](https://blog.csdn.net/dream_broken/article/details/8913563)

### 2.2 优雅停机

Java采用ShutdownHook或SignalHandler方式实现优雅关闭，多数情况下使用ShutdownHook方式，请参考：

[https://blog.csdn.net/carlislelee/article/details/52688693](https://blog.csdn.net/carlislelee/article/details/52688693)

[https://www.cnblogs.com/yougewe/p/9881874.html](https://www.cnblogs.com/yougewe/p/9881874.html)



Java优雅关闭流程：

1）服务启动时注册ShutdownHook

2）服务停止时，用户线程都退出后执行ShutdownHook

3）等待ShutdownHook运行完毕，若干时间后若还没结束则强制退出

请参考：[https://www.cnkirito.moe/gracefully-shutdown/](https://www.cnkirito.moe/gracefully-shutdown/)



对于一般的微服务来说，有这几种任务的入口：Http请求、RPC请求（如dubbo请求）、MQ（如RabbitMQ）消息、定时任务（如xxl-job）等：

对于Http请求，Spring Boot 2.0需要自己写代码实现，请参考2.3节；

对于dubbo请求（如dubbox-2.8.4），需要修改源码，请参考1.2节；

对于RabbitMQ消息，其本身支持优雅停机，但若使用不对会有问题，请参考1.1节；

对于xxl-job定时任务，需要修改点代码，请参考1.1节。

### 2.2 dubbo优雅停机机制

这里假设dubbo注册在ZK上。

1）将服务从集群里摘除，保证不会再被负载到

若本服务是生产者，则将其URL从ZK里delete掉；（ZK会通知那些监听了它的消费者，那么就不会再有消费者请求进来）

若本服务是消费者，则不再监听生产者URL节点数据的变化。



2）对于前面已经进来，还没处理完的rpc请求：

A）若本服务是生产者，则每10ms判断一次是否还有前面进来的消费者的Channal没有结束，若有则等它们结束，默认10s后还有没结束的，则强制全部结束掉

B）若本服务是消费者，则每10ms判断一次是否还有发送出去了但还没响应回来的Channal，若有则等待它们的响应，默认10s后还有没返回的，则强制全部结束掉。



问题：

1）10s内这些出去的或进来的rpc请求若不能处理完，就会有线程被强制kill掉；

2）其它请求（比如http请求、定时任务、MQ消息等）需要自己管理，dubbo只管理了它自己的rpc请求。

### 2.3 Spring Boot优雅停机

SpringBoot官方没有提供优雅停机，需要我们自己写代码实现，请参考：

[https://www.jianshu.com/p/0c49eb23c627](https://www.jianshu.com/p/0c49eb23c627)

### 2.4 微服务优雅停机方案

[https://my.oschina.net/yu120/blog/1788928](https://my.oschina.net/yu120/blog/1788928)

# 二、服务暴露时机

dubbo服务什么时候开始对外提供服务，是否存在应用还没完全启动好就开始对外提供，导致消费方需要等待？若等待超时了是否有failover机制调度到集群里其它服务？

## 1、分析&结论

通过阅读源码或参考[https://www.jianshu.com/p/7f3871492c71](https://www.jianshu.com/p/7f3871492c71)一文可知：dubbo默认会延迟到Spring容器完全启动好后才会对外暴露服务（本地启动NettyServer并将服务注册到Zookeeper上）。

## 2、拓展

有的服务并不能在容器启动完成后立即对外提供服务，可能需要先加载一些较耗时资源，待资源加载完成并发布 ServiceReadyEvent 事件后再对外暴露服务。为了支持这种业务场景，现对dubbo做如下修改。修改前：

```
public void onApplicationEvent(ApplicationEvent event) {
    if (ContextRefreshedEvent.class.getName().equals(event.getClass().getName())) {
       if (isDelay() && ! isExported() && ! isUnexported() && !isLazy()) {
            if (logger.isInfoEnabled()) {
                logger.info("The service ready on spring started. service: " + getInterface());
            }
            export();
        }
    }
}
```

修改后：

```
    if (ContextRefreshedEvent.class.getName().equals(event.getClass().getName())) {
       if (isDelay() && ! isExported() && ! isUnexported() && !isLazy()) {
            if (logger.isInfoEnabled()) {
                logger.info("The service ready on spring started. service: " + getInterface());
            }
            export();
        }
    }

    // 有的服务并不能在容器启动完成后立即对外提供服务，可能需要先加载一些较耗时资源，待资源加载完成并发布 ServiceReadyEvent 事件后再对外暴露服务
    if (ServiceReadyEvent.class.getName().equals(event.getClass().getName())){
        if (isDelay() && ! isExported() && ! isUnexported() && isLazy()) {
            if (logger.isInfoEnabled()) {
                logger.info("The service ready on publish ServiceReadyEvent event. service: " + getInterface());
            }
            export();
        }
    }
}

/**
 * 是否懒暴露，默认false
 */
private boolean isLazy() {
    Boolean lazy = getLazy();
    ProviderConfig provider = getProvider();
    if (lazy == null && provider != null) {
        lazy = provider.getLazy();
    }
    return lazy == null ? false : lazy;
}
```



